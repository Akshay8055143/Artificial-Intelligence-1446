{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0DHzVvQNOpGYcOqdfIn6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshay8055143/Artificial-Intelligence-1446/blob/main/LSTM_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Overview: Build a Text Generation Model using LSTM. The goal is to build a model that can learn language patterns from text and generate new sentence that mimic the training data"
      ],
      "metadata": {
        "id": "z3SItU_Sd8vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5hf9d4hemYR",
        "outputId": "31f32fe8-20cb-46c8-a50f-6664efef6bc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NmPMCT6e2GH",
        "outputId": "c93ac6cd-7545-45eb-a7e2-9fd8f4cef491"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Import all the necessery libraries"
      ],
      "metadata": {
        "id": "z7vgZbuje9rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore')\n",
        "\n",
        "# Preprocess the text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # creates work tokens, number sequences\n",
        "from keras.preprocessing import sequence # padding\n",
        "# Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense,LSTM,Embedding"
      ],
      "metadata": {
        "id": "YgPqT2vxe6Xq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2: Load the dataset"
      ],
      "metadata": {
        "id": "JQaWxiY8fMdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Harry Potter.csv\",'r') as file:\n",
        "  data = file.read()\n",
        "print(data[:70])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoPto8McfJZ_",
        "outputId": "4ae7e594-2a9a-4c3e-d2f0-733ad7b92a7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿Character;Sentence\n",
            "Dumbledore;I should've known that you would be her\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:70]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yBuv8sC_fbtC",
        "outputId": "9f53c06a-11cf-426d-dd0c-e67cba63d0bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ufeffCharacter;Sentence\\nDumbledore;I should've known that you would be her\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3:Tokenization & Sequence Creation"
      ],
      "metadata": {
        "id": "VjAGtuuHyfW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# apply the tokenizer on respective words\n",
        "texts = [\"I should've known that you would be her\"]\n",
        "tokenizer.fit_on_texts(texts) # this is going to develop tokens and their frequency count\n",
        "print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnDXy_4EfeVj",
        "outputId": "d4730f9d-f289-4c03-d21e-f1e43346d5a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, \"should've\": 2, 'known': 3, 'that': 4, 'you': 5, 'would': 6, 'be': 7, 'her': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to give this text to the model\n",
        "# [[1,3,4,5,2],[1,2,6,7]]\n",
        "tokenizer.texts_to_sequences(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUKgWRf8lJd3",
        "outputId": "1638faec-6079-472e-ed5e-0b4519074977"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5, 6, 7, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit on texts - pass the data\n",
        "tokenizer.fit_on_texts([data])\n",
        "word_ind = tokenizer.word_index\n",
        "word_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVcwqL8gmw3t",
        "outputId": "924d52f5-e3bd-4e1b-9dc7-75376ce348db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'harry': 1,\n",
              " 'you': 2,\n",
              " 'the': 3,\n",
              " 'hagrid': 4,\n",
              " 'to': 5,\n",
              " 'ron': 6,\n",
              " 'i': 7,\n",
              " 'a': 8,\n",
              " 'hermione': 9,\n",
              " 'and': 10,\n",
              " 'it': 11,\n",
              " 'of': 12,\n",
              " 'that': 13,\n",
              " 'is': 14,\n",
              " 'dumbledore': 15,\n",
              " 'in': 16,\n",
              " 'what': 17,\n",
              " 'be': 18,\n",
              " 'on': 19,\n",
              " 'this': 20,\n",
              " 'me': 21,\n",
              " 'your': 22,\n",
              " 'not': 23,\n",
              " 'mcgonagall': 24,\n",
              " 'do': 25,\n",
              " \"it's\": 26,\n",
              " 'there': 27,\n",
              " 'for': 28,\n",
              " 'no': 29,\n",
              " 'he': 30,\n",
              " 'but': 31,\n",
              " 'are': 32,\n",
              " 'all': 33,\n",
              " 'go': 34,\n",
              " 'have': 35,\n",
              " 'up': 36,\n",
              " 'snape': 37,\n",
              " \"don't\": 38,\n",
              " 'know': 39,\n",
              " 'now': 40,\n",
              " 'one': 41,\n",
              " 'petunia': 42,\n",
              " 'my': 43,\n",
              " 'was': 44,\n",
              " 'malfoy': 45,\n",
              " 'see': 46,\n",
              " 'with': 47,\n",
              " 'we': 48,\n",
              " 'quirrell': 49,\n",
              " \"i'm\": 50,\n",
              " 'will': 51,\n",
              " 'potter': 52,\n",
              " 'oh': 53,\n",
              " 'vernon': 54,\n",
              " 'well': 55,\n",
              " 'come': 56,\n",
              " 'as': 57,\n",
              " 'right': 58,\n",
              " 'got': 59,\n",
              " 'if': 60,\n",
              " 'voldemort': 61,\n",
              " 'just': 62,\n",
              " \"that's\": 63,\n",
              " 'him': 64,\n",
              " \"you're\": 65,\n",
              " 'like': 66,\n",
              " 'good': 67,\n",
              " 'how': 68,\n",
              " 'about': 69,\n",
              " \"he's\": 70,\n",
              " 'at': 71,\n",
              " 'can': 72,\n",
              " 'here': 73,\n",
              " 'get': 74,\n",
              " 'madam': 75,\n",
              " 'who': 76,\n",
              " 'going': 77,\n",
              " 'hooch': 78,\n",
              " 'think': 79,\n",
              " 'then': 80,\n",
              " 'percy': 81,\n",
              " 'oliver': 82,\n",
              " 'professor': 83,\n",
              " 'filch': 84,\n",
              " 'stone': 85,\n",
              " 'so': 86,\n",
              " 'something': 87,\n",
              " 'out': 88,\n",
              " 'mr': 89,\n",
              " 'his': 90,\n",
              " 'points': 91,\n",
              " 'neville': 92,\n",
              " 'sorting': 93,\n",
              " 'boy': 94,\n",
              " 'they': 95,\n",
              " 'yes': 96,\n",
              " 'hogwarts': 97,\n",
              " 'ollivander': 98,\n",
              " 'hat': 99,\n",
              " 'nicholas': 100,\n",
              " 'would': 101,\n",
              " 'sir': 102,\n",
              " 'off': 103,\n",
              " 'only': 104,\n",
              " 'from': 105,\n",
              " 'why': 106,\n",
              " 'bit': 107,\n",
              " 'never': 108,\n",
              " 'look': 109,\n",
              " 'weasley': 110,\n",
              " 'gryffindor': 111,\n",
              " 'were': 112,\n",
              " 'dudley': 113,\n",
              " 'back': 114,\n",
              " 'first': 115,\n",
              " 'way': 116,\n",
              " \"i've\": 117,\n",
              " 'day': 118,\n",
              " \"we're\": 119,\n",
              " 'she': 120,\n",
              " 'want': 121,\n",
              " 'mean': 122,\n",
              " \"can't\": 123,\n",
              " 'where': 124,\n",
              " \"you'll\": 125,\n",
              " 'course': 126,\n",
              " 'slytherin': 127,\n",
              " 'again': 128,\n",
              " 'firenze': 129,\n",
              " 'really': 130,\n",
              " 'them': 131,\n",
              " 'when': 132,\n",
              " 'make': 133,\n",
              " 'sorry': 134,\n",
              " 'more': 135,\n",
              " 'or': 136,\n",
              " 'down': 137,\n",
              " 'must': 138,\n",
              " 'very': 139,\n",
              " 'lee': 140,\n",
              " 'jordan': 141,\n",
              " 'has': 142,\n",
              " 'name': 143,\n",
              " 'had': 144,\n",
              " 'before': 145,\n",
              " 'did': 146,\n",
              " \"there's\": 147,\n",
              " 'find': 148,\n",
              " \"you've\": 149,\n",
              " 'tell': 150,\n",
              " 'take': 151,\n",
              " 'flitwick': 152,\n",
              " 'bad': 153,\n",
              " 'any': 154,\n",
              " 'help': 155,\n",
              " 'too': 156,\n",
              " \"what's\": 157,\n",
              " 'great': 158,\n",
              " 'please': 159,\n",
              " 'an': 160,\n",
              " 'dragon': 161,\n",
              " '3': 162,\n",
              " 'fred': 163,\n",
              " 'into': 164,\n",
              " 'seamus': 165,\n",
              " 'said': 166,\n",
              " 'game': 167,\n",
              " 'little': 168,\n",
              " 'after': 169,\n",
              " 'gone': 170,\n",
              " 'give': 171,\n",
              " 'us': 172,\n",
              " \"didn't\": 173,\n",
              " 'wizard': 174,\n",
              " 'been': 175,\n",
              " 'told': 176,\n",
              " 'could': 177,\n",
              " 'wait': 178,\n",
              " 'by': 179,\n",
              " 'mrs': 180,\n",
              " 'house': 181,\n",
              " 'quidditch': 182,\n",
              " 'flamel': 183,\n",
              " \"doesn't\": 184,\n",
              " 'thing': 185,\n",
              " \"he'll\": 186,\n",
              " 'man': 187,\n",
              " 'okay': 188,\n",
              " 'knows': 189,\n",
              " 'time': 190,\n",
              " 'george': 191,\n",
              " \"let's\": 192,\n",
              " 'follow': 193,\n",
              " 'ah': 194,\n",
              " \"they're\": 195,\n",
              " 'our': 196,\n",
              " 'better': 197,\n",
              " 'year': 198,\n",
              " 'nice': 199,\n",
              " 'minute': 200,\n",
              " 'magic': 201,\n",
              " 'stop': 202,\n",
              " \"isn't\": 203,\n",
              " 'say': 204,\n",
              " 'three': 205,\n",
              " 'wand': 206,\n",
              " 'welcome': 207,\n",
              " 'hello': 208,\n",
              " 'dark': 209,\n",
              " 'broom': 210,\n",
              " 'most': 211,\n",
              " 'does': 212,\n",
              " 'another': 213,\n",
              " 'few': 214,\n",
              " 'kill': 215,\n",
              " 'yeah': 216,\n",
              " 'everyone': 217,\n",
              " 'keep': 218,\n",
              " 'seeker': 219,\n",
              " 'blood': 220,\n",
              " 'whoa': 221,\n",
              " 'trust': 222,\n",
              " 'life': 223,\n",
              " 'try': 224,\n",
              " 'these': 225,\n",
              " 'people': 226,\n",
              " \"won't\": 227,\n",
              " 'last': 228,\n",
              " 'some': 229,\n",
              " 'move': 230,\n",
              " 'understand': 231,\n",
              " 'their': 232,\n",
              " 'knew': 233,\n",
              " 'parents': 234,\n",
              " 'school': 235,\n",
              " 'hey': 236,\n",
              " 'best': 237,\n",
              " 'bloody': 238,\n",
              " 'let': 239,\n",
              " \"who's\": 240,\n",
              " 'mind': 241,\n",
              " 'am': 242,\n",
              " 'excuse': 243,\n",
              " 'put': 244,\n",
              " 'ooh': 245,\n",
              " 'things': 246,\n",
              " 'years': 247,\n",
              " 'uh': 248,\n",
              " 'yourself': 249,\n",
              " 'ask': 250,\n",
              " 'wrong': 251,\n",
              " 'found': 252,\n",
              " 'even': 253,\n",
              " \"i'll\": 254,\n",
              " 'troll': 255,\n",
              " 'fluffy': 256,\n",
              " 'over': 257,\n",
              " 'famous': 258,\n",
              " 'exactly': 259,\n",
              " 'hurry': 260,\n",
              " 'many': 261,\n",
              " 'myself': 262,\n",
              " 'than': 263,\n",
              " 'two': 264,\n",
              " 'should': 265,\n",
              " 'looking': 266,\n",
              " 'old': 267,\n",
              " 'enough': 268,\n",
              " 'dear': 269,\n",
              " 'fine': 270,\n",
              " 'leave': 271,\n",
              " 'once': 272,\n",
              " 'same': 273,\n",
              " \"i'd\": 274,\n",
              " 'her': 275,\n",
              " 'anyone': 276,\n",
              " 'need': 277,\n",
              " 'those': 278,\n",
              " 'class': 279,\n",
              " 'place': 280,\n",
              " 'gave': 281,\n",
              " 'nothing': 282,\n",
              " 'remember': 283,\n",
              " 'its': 284,\n",
              " 'left': 285,\n",
              " 'girl': 286,\n",
              " 'means': 287,\n",
              " 'afternoon': 288,\n",
              " 'heard': 289,\n",
              " 'done': 290,\n",
              " 'ahh': 291,\n",
              " 'mirror': 292,\n",
              " 'luck': 293,\n",
              " 'anything': 294,\n",
              " \"aren't\": 295,\n",
              " 'dad': 296,\n",
              " 'thanks': 297,\n",
              " \"we'll\": 298,\n",
              " 'happened': 299,\n",
              " 'seen': 300,\n",
              " 'might': 301,\n",
              " 'every': 302,\n",
              " 'father': 303,\n",
              " 'witch': 304,\n",
              " 'met': 305,\n",
              " 'went': 306,\n",
              " 'students': 307,\n",
              " 'sure': 308,\n",
              " 'perhaps': 309,\n",
              " 'which': 310,\n",
              " 'stand': 311,\n",
              " 'still': 312,\n",
              " 'always': 313,\n",
              " 'spell': 314,\n",
              " 'dead': 315,\n",
              " 'curse': 316,\n",
              " 'gonna': 317,\n",
              " '9': 318,\n",
              " '4': 319,\n",
              " 'around': 320,\n",
              " 'turn': 321,\n",
              " 'read': 322,\n",
              " 'forest': 323,\n",
              " 'head': 324,\n",
              " 'eye': 325,\n",
              " 'taken': 326,\n",
              " 'longbottom': 327,\n",
              " \"shouldn't\": 328,\n",
              " 'use': 329,\n",
              " 'guarding': 330,\n",
              " 'snitch': 331,\n",
              " \"we've\": 332,\n",
              " 'thought': 333,\n",
              " 'known': 334,\n",
              " 'important': 335,\n",
              " 'wake': 336,\n",
              " 'safe': 337,\n",
              " 'sort': 338,\n",
              " 'family': 339,\n",
              " 'away': 340,\n",
              " 'happy': 341,\n",
              " 'new': 342,\n",
              " 'snake': 343,\n",
              " 'doing': 344,\n",
              " 'mum': 345,\n",
              " 'such': 346,\n",
              " 'moment': 347,\n",
              " 'today': 348,\n",
              " 'ever': 349,\n",
              " 'scared': 350,\n",
              " 'mother': 351,\n",
              " 'fool': 352,\n",
              " 'real': 353,\n",
              " 'vault': 354,\n",
              " 'griphook': 355,\n",
              " 'curious': 356,\n",
              " 'side': 357,\n",
              " 'tried': 358,\n",
              " 'night': 359,\n",
              " '10': 360,\n",
              " 'platform': 361,\n",
              " 'between': 362,\n",
              " 'besides': 363,\n",
              " 'each': 364,\n",
              " 'begin': 365,\n",
              " 'granger': 366,\n",
              " 'change': 367,\n",
              " 'cup': 368,\n",
              " 'saying': 369,\n",
              " 'draco': 370,\n",
              " 'die': 371,\n",
              " 'relax': 372,\n",
              " \"wasn't\": 373,\n",
              " 'job': 374,\n",
              " 'gryffindors': 375,\n",
              " 'trying': 376,\n",
              " 'listen': 377,\n",
              " 'broomstick': 378,\n",
              " 'catch': 379,\n",
              " 'leviosa': 380,\n",
              " '5': 381,\n",
              " 'live': 382,\n",
              " 'dog': 383,\n",
              " 'fire': 384,\n",
              " 'chess': 385,\n",
              " 'albus': 386,\n",
              " 'afraid': 387,\n",
              " 'comes': 388,\n",
              " 'birthday': 389,\n",
              " 'funny': 390,\n",
              " 'business': 391,\n",
              " 'week': 392,\n",
              " 'either': 393,\n",
              " 'mummy': 394,\n",
              " 'believe': 395,\n",
              " 'stupid': 396,\n",
              " 'letter': 397,\n",
              " 'yours': 398,\n",
              " 'through': 399,\n",
              " 'wish': 400,\n",
              " 'along': 401,\n",
              " 'thank': 402,\n",
              " 'young': 403,\n",
              " 'wonder': 404,\n",
              " 'died': 405,\n",
              " 'killed': 406,\n",
              " 'um': 407,\n",
              " 'stay': 408,\n",
              " 'work': 409,\n",
              " 'against': 410,\n",
              " 'teacher': 411,\n",
              " 'eh': 412,\n",
              " 'gringotts': 413,\n",
              " \"ain't\": 414,\n",
              " 'secret': 415,\n",
              " 'happens': 416,\n",
              " 'other': 417,\n",
              " 'expect': 418,\n",
              " 'seem': 419,\n",
              " 'maybe': 420,\n",
              " 'wicked': 421,\n",
              " 'fat': 422,\n",
              " 'soon': 423,\n",
              " 'join': 424,\n",
              " 'hufflepuff': 425,\n",
              " 'while': 426,\n",
              " 'hand': 427,\n",
              " 'friends': 428,\n",
              " 'floor': 429,\n",
              " 'death': 430,\n",
              " 'thats': 431,\n",
              " 'headless': 432,\n",
              " 'door': 433,\n",
              " 'locked': 434,\n",
              " 'alohomora': 435,\n",
              " 'probably': 436,\n",
              " 'standing': 437,\n",
              " 'bed': 438,\n",
              " 'quaffle': 439,\n",
              " \"wizard's\": 440,\n",
              " 'wingardium': 441,\n",
              " 'dungeon': 442,\n",
              " 'together': 443,\n",
              " 'playing': 444,\n",
              " 'e': 445,\n",
              " 'both': 446,\n",
              " 'past': 447,\n",
              " 'himself': 448,\n",
              " \"snape's\": 449,\n",
              " 'steal': 450,\n",
              " 'romania': 451,\n",
              " 'kind': 452,\n",
              " 'shows': 453,\n",
              " 'play': 454,\n",
              " 'stranger': 455,\n",
              " '50': 456,\n",
              " 'detention': 457,\n",
              " 'unicorn': 458,\n",
              " \"devil's\": 459,\n",
              " 'true': 460,\n",
              " 'leaving': 461,\n",
              " 'muggles': 462,\n",
              " 'world': 463,\n",
              " 'far': 464,\n",
              " 'ready': 465,\n",
              " 'cousin': 466,\n",
              " 'bring': 467,\n",
              " 'buy': 468,\n",
              " 'miss': 469,\n",
              " \"it'll\": 470,\n",
              " 'fit': 471,\n",
              " 'post': 472,\n",
              " \"harry's\": 473,\n",
              " 'mail': 474,\n",
              " 'because': 475,\n",
              " \"haven't\": 476,\n",
              " 'since': 477,\n",
              " 'keeper': 478,\n",
              " 'keys': 479,\n",
              " 'blimey': 480,\n",
              " 'made': 481,\n",
              " 'wizardry': 482,\n",
              " 'took': 483,\n",
              " 'being': 484,\n",
              " 'strange': 485,\n",
              " 'car': 486,\n",
              " 'crash': 487,\n",
              " 'muggle': 488,\n",
              " 'pay': 489,\n",
              " 'teach': 490,\n",
              " 'appreciate': 491,\n",
              " 'allowed': 492,\n",
              " \"you'd\": 493,\n",
              " 'hide': 494,\n",
              " 'love': 495,\n",
              " '2': 496,\n",
              " 'may': 497,\n",
              " 'barkeep\\xa0tom': 498,\n",
              " 'meet': 499,\n",
              " \"here's\": 500,\n",
              " 'except': 501,\n",
              " 'goblins': 502,\n",
              " 'clever': 503,\n",
              " 'key': 504,\n",
              " 'else': 505,\n",
              " 'run': 506,\n",
              " 'long': 507,\n",
              " 'matter': 508,\n",
              " 'feather': 509,\n",
              " 'brother': 510,\n",
              " 'scar': 511,\n",
              " 'speak': 512,\n",
              " 'terrible': 513,\n",
              " 'ago': 514,\n",
              " 'v': 515,\n",
              " 'times': 516,\n",
              " 'mark': 517,\n",
              " 'train': 518,\n",
              " 'stick': 519,\n",
              " 'next': 520,\n",
              " 'honestly': 521,\n",
              " \"ron's\": 522,\n",
              " 'set': 523,\n",
              " 'also': 524,\n",
              " 'lost': 525,\n",
              " 'houses': 526,\n",
              " 'ravenclaw': 527,\n",
              " 'end': 528,\n",
              " 'trevor': 529,\n",
              " 'third': 530,\n",
              " 'hmm': 531,\n",
              " 'ronald': 532,\n",
              " 'attention': 533,\n",
              " 'half': 534,\n",
              " 'nearly': 535,\n",
              " 'dormitories': 536,\n",
              " 'face': 537,\n",
              " 'brilliant': 538,\n",
              " 'potion': 539,\n",
              " 'possession': 540,\n",
              " 'pity': 541,\n",
              " 'save': 542,\n",
              " 'harp': 543,\n",
              " 'weak': 544,\n",
              " 'wanna': 545,\n",
              " 'broken': 546,\n",
              " 'poor': 547,\n",
              " 'wood': 548,\n",
              " 'century': 549,\n",
              " \"one's\": 550,\n",
              " '3rd': 551,\n",
              " 'handle': 552,\n",
              " 'careful': 553,\n",
              " 'forget': 554,\n",
              " 'swish': 555,\n",
              " 'flick': 556,\n",
              " 'leviosar': 557,\n",
              " 'ms': 558,\n",
              " 'ought': 559,\n",
              " 'teachers': 560,\n",
              " 'dungeons': 561,\n",
              " 'ahhh': 562,\n",
              " 'yourselves': 563,\n",
              " \"hadn't\": 564,\n",
              " 'hehe': 565,\n",
              " 'trouble': 566,\n",
              " 'headed': 567,\n",
              " \"hogwarts'\": 568,\n",
              " 'wants': 569,\n",
              " 'flint': 570,\n",
              " 'knight': 571,\n",
              " 'section': 572,\n",
              " 'christmas': 573,\n",
              " 'cloak': 574,\n",
              " 'gives': 575,\n",
              " 'home': 576,\n",
              " 'final': 577,\n",
              " 'hermoine': 578,\n",
              " \"philosopher's\": 579,\n",
              " 'pure': 580,\n",
              " 'elixir': 581,\n",
              " \"sorcerer's\": 582,\n",
              " 'won': 583,\n",
              " 'norbert': 584,\n",
              " 'wanted': 585,\n",
              " 'tonight': 586,\n",
              " 'own': 587,\n",
              " 'fang': 588,\n",
              " 'across': 589,\n",
              " 'lucky': 590,\n",
              " 'snare': 591,\n",
              " 'bravery': 592,\n",
              " 'award': 593,\n",
              " 'evening': 594,\n",
              " 'asleep': 595,\n",
              " 'flying': 596,\n",
              " 'until': 597,\n",
              " 'goodbye': 598,\n",
              " 'zoo': 599,\n",
              " 'everything': 600,\n",
              " 'perfect': 601,\n",
              " \"dudley's\": 602,\n",
              " 'special': 603,\n",
              " 'wonderful': 604,\n",
              " 'darling': 605,\n",
              " '36': 606,\n",
              " 'quite': 607,\n",
              " \"year's\": 608,\n",
              " 'care': 609,\n",
              " 'big': 610,\n",
              " 'presents': 611,\n",
              " 'lovely': 612,\n",
              " 'forward': 613,\n",
              " 'warning': 614,\n",
              " 'hear': 615,\n",
              " 'talked': 616,\n",
              " 'often': 617,\n",
              " 'someone': 618,\n",
              " 'glass': 619,\n",
              " 'smeltings': 620,\n",
              " 'state': 621,\n",
              " 'wearing': 622,\n",
              " 'bits': 623,\n",
              " 'skin': 624,\n",
              " 'mine': 625,\n",
              " 'sunday': 626,\n",
              " 'opinion': 627,\n",
              " 'blasted': 628,\n",
              " 'letters': 629,\n",
              " 'single': 630,\n",
              " 'happening': 631,\n",
              " 'mad': 632,\n",
              " \"hasn't\": 633,\n",
              " 'breaking': 634,\n",
              " 'baby': 635,\n",
              " 'expected': 636,\n",
              " 'particularly': 637,\n",
              " 'imagine': 638,\n",
              " 'words': 639,\n",
              " 'turns': 640,\n",
              " 'trained': 641,\n",
              " 'mistake': 642,\n",
              " 'happen': 643,\n",
              " \"couldn't\": 644,\n",
              " 'explain': 645,\n",
              " 'pleased': 646,\n",
              " 'witchcraft': 647,\n",
              " 'herself': 648,\n",
              " 'blown': 649,\n",
              " 'suppose': 650,\n",
              " 'finest': 651,\n",
              " 'under': 652,\n",
              " 'front': 653,\n",
              " 'rather': 654,\n",
              " 'robes': 655,\n",
              " 'pair': 656,\n",
              " 'vastly': 657,\n",
              " 'misunderstood': 658,\n",
              " 'beasts': 659,\n",
              " 'standard': 660,\n",
              " 'desire': 661,\n",
              " 'owl': 662,\n",
              " 'cat': 663,\n",
              " 'toad': 664,\n",
              " 'london': 665,\n",
              " 'bless': 666,\n",
              " 'soul': 667,\n",
              " 'arts': 668,\n",
              " 'person': 669,\n",
              " 'quills': 670,\n",
              " 'nimbus': 671,\n",
              " '2000': 672,\n",
              " 'money': 673,\n",
              " 'goblin': 674,\n",
              " 'somewhere': 675,\n",
              " 'ya': 676,\n",
              " '713': 677,\n",
              " 'seems': 678,\n",
              " 'yesterday': 679,\n",
              " 'apparently': 680,\n",
              " 'tail': 681,\n",
              " 'clear': 682,\n",
              " 'named': 683,\n",
              " 'quiet': 684,\n",
              " 'wizards': 685,\n",
              " 'gather': 686,\n",
              " 'brought': 687,\n",
              " 'stood': 688,\n",
              " 'nobody': 689,\n",
              " 'lived': 690,\n",
              " 'decided': 691,\n",
              " 'touched': 692,\n",
              " 'evil': 693,\n",
              " 'codswallop': 694,\n",
              " 'wanting': 695,\n",
              " 'leaves': 696,\n",
              " 'minutes': 697,\n",
              " 'ticket': 698,\n",
              " 'trainmaster': 699,\n",
              " 'packed': 700,\n",
              " 'woman': 701,\n",
              " 'call': 702,\n",
              " 'onto': 703,\n",
              " 'worry': 704,\n",
              " 'walk': 705,\n",
              " 'straight': 706,\n",
              " 'full': 707,\n",
              " 'lot': 708,\n",
              " 'bertie': 709,\n",
              " \"bott's\": 710,\n",
              " 'flavor': 711,\n",
              " 'beans': 712,\n",
              " 'chocolate': 713,\n",
              " 'flavoured': 714,\n",
              " 'frogs': 715,\n",
              " 'cards': 716,\n",
              " 'watch': 717,\n",
              " \"they've\": 718,\n",
              " 'jump': 719,\n",
              " 'hang': 720,\n",
              " 'pathetic': 721,\n",
              " 'yellow': 722,\n",
              " \"neville's\": 723,\n",
              " 'simple': 724,\n",
              " 'example': 725,\n",
              " 'classmates': 726,\n",
              " 'seats': 727,\n",
              " 'sorted': 728,\n",
              " 'awarded': 729,\n",
              " 'red': 730,\n",
              " 'others': 731,\n",
              " 'making': 732,\n",
              " 'bewitched': 733,\n",
              " 'start': 734,\n",
              " 'note': 735,\n",
              " 'strictly': 736,\n",
              " 'forbidden': 737,\n",
              " 'asked': 738,\n",
              " 'telling': 739,\n",
              " 'difficult': 740,\n",
              " 'courage': 741,\n",
              " 'nasty': 742,\n",
              " 'potions': 743,\n",
              " 'fancies': 744,\n",
              " 'staircases': 745,\n",
              " 'quickly': 746,\n",
              " 'moving': 747,\n",
              " 'room': 748,\n",
              " 'already': 749,\n",
              " 'late': 750,\n",
              " 'pocket': 751,\n",
              " 'foolish': 752,\n",
              " 'silly': 753,\n",
              " 'however': 754,\n",
              " 'fame': 755,\n",
              " 'feel': 756,\n",
              " 'asphodel': 757,\n",
              " 'wormwood': 758,\n",
              " 'bezoar': 759,\n",
              " 'monkshood': 760,\n",
              " 'wolfsbane': 761,\n",
              " 'clearly': 762,\n",
              " 'information': 763,\n",
              " 'living': 764,\n",
              " 'plant': 765,\n",
              " 'rabbit': 766,\n",
              " 'water': 767,\n",
              " 'rum': 768,\n",
              " 'borrow': 769,\n",
              " 'forgotten': 770,\n",
              " 'problem': 771,\n",
              " 'question': 772,\n",
              " 'fact': 773,\n",
              " 'odd': 774,\n",
              " 'whistle': 775,\n",
              " 'ground': 776,\n",
              " 'touch': 777,\n",
              " 'wrist': 778,\n",
              " 'feet': 779,\n",
              " 'hospital': 780,\n",
              " 'wing': 781,\n",
              " 'given': 782,\n",
              " \"he'd\": 783,\n",
              " 'fly': 784,\n",
              " 'youngest': 785,\n",
              " 'according': 786,\n",
              " 'beaters': 787,\n",
              " 'played': 788,\n",
              " 'moves': 789,\n",
              " 'spells': 790,\n",
              " 'preoccupied': 791,\n",
              " 'notice': 792,\n",
              " 'worse': 793,\n",
              " 'needs': 794,\n",
              " 'easy': 795,\n",
              " 'players': 796,\n",
              " 'chasers': 797,\n",
              " 'hoops': 798,\n",
              " 'bludger': 799,\n",
              " 'ball': 800,\n",
              " 'golden': 801,\n",
              " 'near': 802,\n",
              " 'win': 803,\n",
              " \"someone's\": 804,\n",
              " \"girl's\": 805,\n",
              " 'bathroom': 806,\n",
              " 'panic': 807,\n",
              " 'whooa': 808,\n",
              " 'cool': 809,\n",
              " 'ew': 810,\n",
              " 'realize': 811,\n",
              " 'grown': 812,\n",
              " 'm': 813,\n",
              " 'mate': 814,\n",
              " 'strength': 815,\n",
              " 'worth': 816,\n",
              " '150': 817,\n",
              " 'takes': 818,\n",
              " 'captain': 819,\n",
              " 'yay': 820,\n",
              " 'crowd': 821,\n",
              " 'jinxing': 822,\n",
              " 'looks': 823,\n",
              " 'whoo': 824,\n",
              " 'halloween': 825,\n",
              " 'pub': 826,\n",
              " 'questions': 827,\n",
              " 'whatever': 828,\n",
              " \"fluffy's\": 829,\n",
              " 'contact': 830,\n",
              " 'queen': 831,\n",
              " 'visit': 832,\n",
              " 'charlie': 833,\n",
              " 'dragons': 834,\n",
              " 'looked': 835,\n",
              " 'restricted': 836,\n",
              " 'perfectly': 837,\n",
              " 'chat': 838,\n",
              " 'student': 839,\n",
              " 'holding': 840,\n",
              " 'neither': 841,\n",
              " 'truth': 842,\n",
              " 'exams': 843,\n",
              " 'coming': 844,\n",
              " 'countercurse': 845,\n",
              " 'weeks': 846,\n",
              " 'light': 847,\n",
              " 'reading': 848,\n",
              " 'immortal': 849,\n",
              " 'shh': 850,\n",
              " 'trapdoor': 851,\n",
              " 'four': 852,\n",
              " 'god': 853,\n",
              " 'inside': 854,\n",
              " 'werewolves': 855,\n",
              " 'beast': 856,\n",
              " 'ahhhhhhhhh': 857,\n",
              " 'creatures': 858,\n",
              " 'especially': 859,\n",
              " 'saved': 860,\n",
              " 'drinking': 861,\n",
              " 'strong': 862,\n",
              " \"dumbledore's\": 863,\n",
              " 'interested': 864,\n",
              " 'immediately': 865,\n",
              " 'scary': 866,\n",
              " 'ugh': 867,\n",
              " 'faster': 868,\n",
              " 'herbology': 869,\n",
              " 'birds': 870,\n",
              " 'graveyard': 871,\n",
              " 'castle': 872,\n",
              " 'check': 873,\n",
              " 'p': 874,\n",
              " 'alone': 875,\n",
              " 'lies': 876,\n",
              " 'cannot': 877,\n",
              " 'return': 878,\n",
              " 'admirers': 879,\n",
              " 'friend': 880,\n",
              " 'order': 881,\n",
              " 'second': 882,\n",
              " 'deal': 883,\n",
              " '\\ufeffcharacter': 884,\n",
              " 'sentence': 885,\n",
              " \"should've\": 886,\n",
              " 'rumors': 887,\n",
              " 'bringing': 888,\n",
              " 'wise': 889,\n",
              " 'problems': 890,\n",
              " 'tyke': 891,\n",
              " 'fell': 892,\n",
              " 'bristol': 893,\n",
              " 'watched': 894,\n",
              " 'worst': 895,\n",
              " 'imaginable': 896,\n",
              " 'child': 897,\n",
              " 'growing': 898,\n",
              " 'son': 899,\n",
              " 'cook': 900,\n",
              " 'breakfast': 901,\n",
              " 'burn': 902,\n",
              " 'aunt': 903,\n",
              " 'coffee': 904,\n",
              " 'uncle': 905,\n",
              " 'counted': 906,\n",
              " '37': 907,\n",
              " 'bigger': 908,\n",
              " \"how's\": 909,\n",
              " 'pumpkin': 910,\n",
              " 'meals': 911,\n",
              " 'boring': 912,\n",
              " 'lying': 913,\n",
              " 'watching': 914,\n",
              " 'press': 915,\n",
              " 'ugly': 916,\n",
              " 'faces': 917,\n",
              " 'talk': 918,\n",
              " 'burma': 919,\n",
              " 'anytime': 920,\n",
              " 'ls': 921,\n",
              " 'sweetheart': 922,\n",
              " 'cold': 923,\n",
              " 'clothes': 924,\n",
              " 'swear': 925,\n",
              " 'smile': 926,\n",
              " 'caveat': 927,\n",
              " 'smeltonia': 928,\n",
              " 'proudest': 929,\n",
              " 'wear': 930,\n",
              " 'belong': 931,\n",
              " 'finish': 932,\n",
              " 'dyeing': 933,\n",
              " 'uniform': 934,\n",
              " 'elephant': 935,\n",
              " 'marge': 936,\n",
              " 'ill': 937,\n",
              " 'ate': 938,\n",
              " 'whelk': 939,\n",
              " \"who'd\": 940,\n",
              " 'writing': 941,\n",
              " 'letterbox': 942,\n",
              " 'office': 943,\n",
              " 'shoo': 944,\n",
              " 'sundays': 945,\n",
              " 'miserable': 946,\n",
              " \"daddy's\": 947,\n",
              " 'demand': 948,\n",
              " 'entering': 949,\n",
              " 'dry': 950,\n",
              " 'dursley': 951,\n",
              " 'prune': 952,\n",
              " \"'round\": 953,\n",
              " 'middle': 954,\n",
              " 'sat': 955,\n",
              " 'somepoint': 956,\n",
              " 'taste': 957,\n",
              " 'baked': 958,\n",
              " '11': 959,\n",
              " 'rubeus': 960,\n",
              " 'grounds': 961,\n",
              " 'learned': 962,\n",
              " 'learnt': 963,\n",
              " 'thumping': 964,\n",
              " 'wager': 965,\n",
              " 'l': 966,\n",
              " 'angry': 967,\n",
              " 'inform': 968,\n",
              " 'accepted': 969,\n",
              " 'swore': 970,\n",
              " \"we'd\": 971,\n",
              " 'rubbish': 972,\n",
              " 'sister': 973,\n",
              " 'proud': 974,\n",
              " 'freak': 975,\n",
              " 'abnormal': 976,\n",
              " 'landed': 977,\n",
              " 'lily': 978,\n",
              " 'james': 979,\n",
              " 'outrage': 980,\n",
              " 'scandal': 981,\n",
              " \"yourself's\": 982,\n",
              " 'non': 983,\n",
              " 'folk': 984,\n",
              " \"boy's\": 985,\n",
              " 'born': 986,\n",
              " 'headmaster': 987,\n",
              " 'crackpot': 988,\n",
              " 'tricks': 989,\n",
              " 'insult': 990,\n",
              " 'strickly': 991,\n",
              " 'speaking': 992,\n",
              " 'behind': 993,\n",
              " 'schedule': 994,\n",
              " 'unless': 995,\n",
              " 'require': 996,\n",
              " 'sets': 997,\n",
              " 'plain': 998,\n",
              " 'essential': 999,\n",
              " 'equipment': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texts on Sequence"
      ],
      "metadata": {
        "id": "1R3kmwj_m6uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_length = len(word_ind) + 1\n",
        "# to reserve for padding"
      ],
      "metadata": {
        "id": "vHnn9-eLm2Bo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxz3AMB6nAaQ",
        "outputId": "25c6739b-4a52-4bfb-ac6b-4a86a4ecd39d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1794"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in data.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  # [4,5,6,7]\n",
        "  for i in range(1,len(token_list)): # for i in range(1,4)\n",
        "    n_gram_sequence = token_list[:i+1] # token_list[0:2] = 0th index,1st index\n",
        "    # token_list[0:3] = 0th index,1st index,2nd index\n",
        "    # token_list[0:4] = 0th index, 1st index, 2nd index, 3rd index\n",
        "    input_sequences.append(n_gram_sequence) # [[4,5],[4,5,6],[4,5,6,7]]\n",
        "print(input_sequences[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWZcb7rNnDnY",
        "outputId": "2b59ffbb-48dd-480d-e070-f0dcf0a27cc9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[884, 885], [15, 7], [15, 7, 886], [15, 7, 886, 334], [15, 7, 886, 334, 13], [15, 7, 886, 334, 13, 2], [15, 7, 886, 334, 13, 2, 101], [15, 7, 886, 334, 13, 2, 101, 18], [15, 7, 886, 334, 13, 2, 101, 18, 73], [15, 7, 886, 334, 13, 2, 101, 18, 73, 83], [15, 7, 886, 334, 13, 2, 101, 18, 73, 83, 24], [24, 67], [24, 67, 594], [24, 67, 594, 83], [24, 67, 594, 83, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## padding to bring all the ngram tokens to same size. to bring all the setences to same length"
      ],
      "metadata": {
        "id": "mPR7bIcjnOUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max([80,79,66])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W_Wk2zEnIEO",
        "outputId": "5ed71829-4a06-4466-ae2b-b80502e5a634"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(lines) for lines in input_sequences])\n",
        "\n",
        "input_sequences = sequence.pad_sequences(input_sequences,maxlen=max_length)\n",
        "input_sequences[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbnlYf11nVd7",
        "outputId": "f720c97a-40ba-422f-d1a6-8373a09acf55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 884, 885],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15,   7],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  15,   7, 886],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  15,   7, 886, 334],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,  15,   7, 886, 334,  13],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,  15,   7, 886, 334,  13,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  15,   7, 886, 334,  13,   2, 101],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  15,   7, 886, 334,  13,   2, 101,  18],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  15,   7, 886, 334,  13,   2, 101,  18,  73],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  15,   7, 886, 334,  13,   2, 101,  18,  73,  83],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  15,   7, 886, 334,  13,   2, 101,  18,  73,  83,  24],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24,  67],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  24,  67, 594],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  24,  67, 594,  83],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,  24,  67, 594,  83,  15]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfcZKBfAnaD4",
        "outputId": "66e34b38-0b9f-4121-c3e0-7d9845f6269f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seperate X and Y"
      ],
      "metadata": {
        "id": "1x3V3zqtngoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_sequences[:,:-1]\n",
        "y = input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "F38xdMpVnfjI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_akgtMAnldC",
        "outputId": "6b7de8ba-4d5b-4819-cc07-223df78bba91"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 884],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  15,   7],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  15,   7, 886],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,  15,   7, 886, 334],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,  15,   7, 886, 334,  13],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  15,   7, 886, 334,  13,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  15,   7, 886, 334,  13,   2, 101],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  15,   7, 886, 334,  13,   2, 101,  18],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  15,   7, 886, 334,  13,   2, 101,  18,  73]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucwXQe9-nnvW",
        "outputId": "94e69ba4-7e25-407a-ffad-3ab55f1cdcba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([885,   7, 886, 334,  13,   2, 101,  18,  73,  83], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URQS01OFnsG-",
        "outputId": "baff54c5-3adf-45d1-b7de-32ac7601665c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9707,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "iq_r0sOQn1BM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Provide the input as max length indicating total number of sentences\n",
        "model.add(Input((max_length,)))\n",
        "# Add the layers\n",
        "model.add(Embedding(input_dim=total_length,output_dim=300,trainable=False))\n",
        "model.add(LSTM(200,return_sequences=True,dropout=0.3)) # return sequences will provide the sequences to next LSTM layer\n",
        "model.add(LSTM(150,dropout=0.2))\n",
        "# Add one Hidden layer\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "# Add output layer\n",
        "model.add(Dense(total_length, activation='softmax'))"
      ],
      "metadata": {
        "id": "MUsO1JKAnu22"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0pxQTBuwn-JY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='accuracy',patience=5)"
      ],
      "metadata": {
        "id": "Lv4JPuUYoHH3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = model.fit(x,y,validation_split=0.2,epochs=20,callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0BZzmB8oLBO",
        "outputId": "b7460ac1-89a0-44b0-e401-529a95db161b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0744 - loss: 4.9209 - val_accuracy: 0.0505 - val_loss: 7.0140\n",
            "Epoch 2/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0797 - loss: 4.8377 - val_accuracy: 0.0515 - val_loss: 7.0696\n",
            "Epoch 3/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0851 - loss: 4.7692 - val_accuracy: 0.0530 - val_loss: 7.1100\n",
            "Epoch 4/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.0840 - loss: 4.6944 - val_accuracy: 0.0520 - val_loss: 7.1606\n",
            "Epoch 5/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1014 - loss: 4.6290 - val_accuracy: 0.0494 - val_loss: 7.2435\n",
            "Epoch 6/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1011 - loss: 4.5647 - val_accuracy: 0.0520 - val_loss: 7.3036\n",
            "Epoch 7/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1058 - loss: 4.4862 - val_accuracy: 0.0499 - val_loss: 7.2804\n",
            "Epoch 8/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1137 - loss: 4.4399 - val_accuracy: 0.0546 - val_loss: 7.3622\n",
            "Epoch 9/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.1162 - loss: 4.3541 - val_accuracy: 0.0505 - val_loss: 7.3972\n",
            "Epoch 10/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1173 - loss: 4.3226 - val_accuracy: 0.0494 - val_loss: 7.4299\n",
            "Epoch 11/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1406 - loss: 4.2171 - val_accuracy: 0.0551 - val_loss: 7.5176\n",
            "Epoch 12/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1382 - loss: 4.1717 - val_accuracy: 0.0510 - val_loss: 7.5223\n",
            "Epoch 13/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.1564 - loss: 4.0947 - val_accuracy: 0.0474 - val_loss: 7.5551\n",
            "Epoch 14/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.1589 - loss: 4.0465 - val_accuracy: 0.0525 - val_loss: 7.6045\n",
            "Epoch 15/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1663 - loss: 3.9722 - val_accuracy: 0.0530 - val_loss: 7.6409\n",
            "Epoch 16/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1677 - loss: 3.9370 - val_accuracy: 0.0515 - val_loss: 7.7091\n",
            "Epoch 17/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.1749 - loss: 3.8843 - val_accuracy: 0.0494 - val_loss: 7.7151\n",
            "Epoch 18/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2026 - loss: 3.7985 - val_accuracy: 0.0530 - val_loss: 7.7959\n",
            "Epoch 19/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1928 - loss: 3.7885 - val_accuracy: 0.0556 - val_loss: 7.8258\n",
            "Epoch 20/20\n",
            "\u001b[1m243/243\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.2100 - loss: 3.6987 - val_accuracy: 0.0525 - val_loss: 7.8698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation Function"
      ],
      "metadata": {
        "id": "mFdl0UVvy95x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "def generate_text(seed_text, next_words=50):\n",
        "    for _ in range(next_words):\n",
        "        # preparing our seed text ready for the model\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = sequence.pad_sequences([token_list],maxlen=max_length-1)\n",
        "        # give the proceesed text to model for prediction of next 50words\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0)) # it gives you the index of next word\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                seed_text += ' ' + word\n",
        "                break\n",
        "\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "iChHPWEiqKUB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Output"
      ],
      "metadata": {
        "id": "VNHUmUJzzFHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = \"the king\"\n",
        "generated_text = generate_text(seed, 50)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXnkoB1cxev8",
        "outputId": "db1b220d-6c3c-4b45-bc87-b2077a0724d7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the king of a legendary of a unicorn and at to hogwarts to kill you are you flamel to themselves you flamel while nicholas of course flamel arse in the golden snitch of their rubbish celebrated that to even themselves of the pub wing corridor is death death death death death death\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbmJf5kXxz1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}